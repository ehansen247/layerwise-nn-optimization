{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "474a3be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: accelerate in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (0.15.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from accelerate) (5.4.1)\n",
      "Requirement already satisfied: torch>=1.4.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from accelerate) (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from accelerate) (1.21.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from packaging>=20.0->accelerate) (3.0.7)\n",
      "Requirement already satisfied: future in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from torch>=1.4.0->accelerate) (0.18.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "96df242f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T16:45:28.421190Z",
     "start_time": "2022-12-08T16:45:28.417504Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from collections import OrderedDict\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "22816f1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T16:45:28.735298Z",
     "start_time": "2022-12-08T16:45:28.732350Z"
    }
   },
   "outputs": [],
   "source": [
    "import accelerate\n",
    "import models\n",
    "import importlib\n",
    "import helper\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e7ac06c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T16:45:28.955190Z",
     "start_time": "2022-12-08T16:45:28.951090Z"
    }
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e8536099",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T16:45:29.350232Z",
     "start_time": "2022-12-08T16:45:29.346614Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1707c792",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T17:04:05.927852Z",
     "start_time": "2022-12-08T17:04:05.925620Z"
    }
   },
   "outputs": [],
   "source": [
    "workdir = '/Users/erichansen/Desktop/Classes/9.520/project/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69177085",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3bf23c66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T16:10:31.735295Z",
     "start_time": "2022-12-08T16:10:31.728658Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "global_config = config.get_global_configuration()\n",
    "device = global_config['device']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "6887a498",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T17:06:10.594633Z",
     "start_time": "2022-12-08T17:06:10.582324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'config' from '/Users/erichansen/Dropbox/Mac/Desktop/Classes/9.520/project/config.py'>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(models)\n",
    "importlib.reload(helper)\n",
    "importlib.reload(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d3b71ee4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T08:15:21.733294Z",
     "start_time": "2022-12-08T08:15:21.717739Z"
    }
   },
   "outputs": [],
   "source": [
    "m1 = models.LayerwiseConfigurableCNN()\n",
    "m2 = models.LayerwiseConfigurableMLP()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77953e2",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "7d468c72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T17:06:36.440506Z",
     "start_time": "2022-12-08T17:06:36.424049Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_top1_pos(outputs, targets):\n",
    "    pred = np.argmax(outputs, axis=1)\n",
    "    assert(len(pred) == len(targets))\n",
    "    \n",
    "    return np.sum(np.where(pred == targets, 1, 0))\n",
    "\n",
    "def get_top5_pos(outputs, targets):\n",
    "    sm = 0\n",
    "    for i in range(len(targets)):\n",
    "        top_5 = np.argpartition(outputs[i], -5)[-5:]\n",
    "        sm += 1 if targets[i] in set(top_5) else 0 \n",
    "    \n",
    "    return sm\n",
    "\n",
    "def evaluate_model(model, data_loader, loss_function, device='cpu'):    \n",
    "    output_data = []\n",
    "    targets_data = []\n",
    "    current_loss = 0\n",
    "    \n",
    "    for i, data in enumerate(data_loader):\n",
    "        inputs, targets = data\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # Perform forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        if str(device) != 'cpu':\n",
    "            outputs = outputs.cpu()\n",
    "            targets = targets.cpu()\n",
    "            \n",
    "        output_data.extend(outputs.detach().numpy())\n",
    "        targets_data.extend(targets.detach().numpy())\n",
    "\n",
    "        loss = loss_function(outputs, targets)\n",
    "        current_loss += loss.item()\n",
    "        \n",
    "    N = len(targets_data)\n",
    "    top1_acc = get_top1_pos(output_data, targets_data) / N\n",
    "    top5_acc = get_top5_pos(output_data, targets_data) / N\n",
    "    \n",
    "    return current_loss / float(N), top1_acc, top5_acc    \n",
    "\n",
    "\n",
    "def train_model(model, device='cpu', epochs=None, invariant=False, debug=False):\n",
    "    \"\"\" Train a model. \"\"\"\n",
    "    model_config = config.get_model_configuration()\n",
    "    \n",
    "    loss_function = model_config.get(\"loss_function\")()\n",
    "    optimizer = model_config.get(\"optimizer\")(model.parameters(), \n",
    "                                              lr=model_config.get('learning_rate'),\n",
    "                                              weight_decay=model_config.get('weight_decay'))\n",
    "    trainloader = helper.get_dataset(train=True, invariant=invariant)\n",
    "    testloader = helper.get_dataset(train=False, invariant=invariant)\n",
    "\n",
    "#     Accelerate model\n",
    "#     accelerator = accelerate.Accelerator()  \n",
    "#     model, optimizer, trainloader = accelerator.prepare(model, optimizer, trainloader)\n",
    "\n",
    "    # Iterate over the number of epochs\n",
    "    entries = []\n",
    "    \n",
    "    if epochs is None:\n",
    "        epochs = model_config.get(\"num_epochs\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Print epoch\n",
    "        print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "        # Set current loss value\n",
    "        current_loss = 0.0\n",
    "        \n",
    "        output_data = []\n",
    "        targets_data = []\n",
    " \n",
    "        # Iterate over the DataLoader for training data\n",
    "        st_time = time.time()\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "#             print(i)\n",
    "\n",
    "            # Get inputs\n",
    "            inputs, targets = data\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Perform forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_function(outputs, targets)\n",
    "\n",
    "            current_loss += loss.item()\n",
    "            \n",
    "            # Perform backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Perform optimization\n",
    "            optimizer.step()\n",
    "\n",
    "        end_time = time.time()\n",
    "        \n",
    "        if epoch % 5 == 0 or epoch == (epochs - 1):\n",
    "            test_loss, test_top1_acc, test_top5_acc = evaluate_model(model, testloader ,loss_function)\n",
    "            train_loss, train_top1_acc, train_top5_acc = evaluate_model(model, trainloader ,loss_function)\n",
    "            print(f'Train Acc: {train_top1_acc}')\n",
    "            print(f'Test Acc: {test_top1_acc}')\n",
    "        else:\n",
    "            test_loss, test_top1_acc, test_top5_acc = pd.NA, pd.NA, pd.NA\n",
    "            train_loss, train_top1_acc, train_top5_acc = pd.NA, pd.NA, pd.NA\n",
    "        \n",
    "        elapsed_time = round(end_time - st_time, 1)\n",
    "        train_entry = {'type': 'train', 'epoch': epoch, 'top1': train_top1_acc, 'top5': train_top5_acc,\n",
    "                       'loss': current_loss, 'time': elapsed_time}\n",
    "        \n",
    "        print(f'Loss: {current_loss}')\n",
    "        print(f'Time: {elapsed_time}')\n",
    "\n",
    "        test_entry = {'type': 'test', 'epoch': epoch, 'top1': test_top1_acc, 'top5': test_top5_acc,\n",
    "                      'loss': test_loss, 'time': pd.NA}\n",
    "        \n",
    "        entries.extend([train_entry, test_entry])\n",
    "        \n",
    "        break\n",
    "\n",
    "\n",
    "    # Return trained model\n",
    "    return model, pd.DataFrame(entries), current_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8281b66e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T17:06:36.646433Z",
     "start_time": "2022-12-08T17:06:36.642963Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn = models.LayerwiseConfigurableCNN()\n",
    "# mlp = mlp.to(device)\n",
    "# cnn, cnn_df, loss = train_model(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "2fdd5946",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T17:06:36.818028Z",
     "start_time": "2022-12-08T17:06:36.811832Z"
    }
   },
   "outputs": [],
   "source": [
    "mlp = models.LayerwiseConfigurableMLP()\n",
    "# mlp = mlp.to(device)\n",
    "# mlp, mlp_df, loss = train_model(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "89a7d402",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T17:06:36.973361Z",
     "start_time": "2022-12-08T17:06:36.968851Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_config_columns(results_df):\n",
    "    model_config = config.get_model_configuration()\n",
    "    results_df['optimizer'] = str(model_config['optimizer'])\n",
    "    results_df['hidden_layer_dim'] = model_config['hidden_layer_dim']\n",
    "    results_df['batch_size'] = model_config['batch_size']\n",
    "    results_df['batch_norm'] = model_config['batch_norm']\n",
    "    results_df['weight_decay'] = model_config['weight_decay']\n",
    "    results_df['learning_rate'] = model_config['learning_rate']\n",
    "    results_df['invariant'] = global_config['invariant']\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "fccf8e25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T17:06:37.143376Z",
     "start_time": "2022-12-08T17:06:37.134784Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def greedy_layerwise_training(model, rnd=0):\n",
    "    \"\"\" Perform greedy layer-wise training. \"\"\"    \n",
    "    print(\"NEW!\")\n",
    "    global_config = config.get_global_configuration()\n",
    "    device = global_config.get('device')\n",
    "    model = model.to(device)\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    # Loss comparison\n",
    "    loss_comparable = float('inf')\n",
    "\n",
    "    # Iterate over the number of layers to add\n",
    "    training_losses = []\n",
    "    top5_accs = []\n",
    "    top1_accs = []\n",
    "    \n",
    "    dfs = []\n",
    "    for num_layers in range(global_config.get(\"num_layers_to_add\")):\n",
    "        if len(model.hidden_blocks) < num_layers:\n",
    "            # Add layer to model\n",
    "            model.add_hidden_block()\n",
    "            model = model.to(device)\n",
    "        \n",
    "        active_layer = model.input_block if num_layers == 0 else model.hidden_block[num_layers - 1]\n",
    "        model.activate_layers([active_layer])\n",
    "        if num_layers > 0:\n",
    "            model.freeze_layers([model.input_block] + [model.hidden_blocks[i] for i in range(num_layers-1)])\n",
    "        \n",
    "        # Print which model is trained\n",
    "        print(\"=\"*100)\n",
    "        if num_layers > 0:\n",
    "            print(f\">>> TRAINING THE MODEL WITH {num_layers} ADDITIONAL LAYERS:\")\n",
    "        else:\n",
    "            print(f\">>> TRAINING THE BASE MODEL:\")\n",
    "\n",
    "        # Train the model\n",
    "        model, df, end_loss = train_model(model, device=device, invariant=global_config['invariant'])\n",
    "        df['layer'] = num_layers\n",
    "        df['layer_params'] = model.num_trainable_weights()\n",
    "        dfs.append(df)\n",
    "\n",
    "        # Compare loss\n",
    "        if num_layers > 0 and end_loss < loss_comparable:\n",
    "            print(\"=\"*50)\n",
    "            print(f\">>> RESULTS: Adding this layer has improved the model loss from {loss_comparable} to {end_loss}\")\n",
    "            loss_comparable = end_loss\n",
    "        elif num_layers > 0:\n",
    "            print(\"=\"*50)\n",
    "            print(f\">>> RESULTS: Adding this layer did not improve the model loss from {loss_comparable} to {end_loss}\")\n",
    "        elif num_layers == 0:\n",
    "            loss_comparable = end_loss\n",
    "\n",
    "        # Add layer to model\n",
    "        break\n",
    "\n",
    "    # Process is complete\n",
    "    print(\"Training process has finished.\")\n",
    "    \n",
    "    results_df = pd.concat(dfs)\n",
    "    results_df = add_config_columns(results_df)\n",
    "    results_df['model'] = model.get_name()\n",
    "\n",
    "    \n",
    "    return model, results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "78b0547e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T17:06:37.395801Z",
     "start_time": "2022-12-08T17:06:37.388565Z"
    }
   },
   "outputs": [],
   "source": [
    "def full_backprop_training(model):\n",
    "    \"\"\" Perform greedy layer-wise training. \"\"\"    \n",
    "    print(\"NEW!\")\n",
    "    global_config = config.get_global_configuration()\n",
    "    device = global_config.get('device')\n",
    "    model = model.to(device)\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    # Loss comparison\n",
    "    loss_comparable = float('inf')\n",
    "\n",
    "    # Iterate over the number of layers to add\n",
    "    training_losses = []\n",
    "    top5_accs = []\n",
    "    top1_accs = []\n",
    "    \n",
    "    dfs = []\n",
    "    for i in range(global_config.get(\"num_layers_to_add\")):        \n",
    "        model = model.to(device)\n",
    "        model, df, end_loss = train_model(model, device=device, invariant=global_config['invariant'])\n",
    "        print(i)\n",
    "        print(end_loss)\n",
    "\n",
    "        df['layer'] = len(model.hidden_blocks)\n",
    "        df['layer_params'] = model.num_trainable_weights()\n",
    "        dfs.append(df)\n",
    "        \n",
    "        model.add_hidden_block()\n",
    "        break\n",
    "    \n",
    "    results_df = pd.concat(dfs)\n",
    "    results_df = add_config_columns(results_df)\n",
    "    results_df['model'] = model.get_name()\n",
    "    \n",
    "    dt = datetime.datetime.now()\n",
    "    results_df.to_csv(workdir + f'results/{str(dt.strftime(\"%Y-%m-%d-%H-%M\"))}.csv')\n",
    "    \n",
    "    return model, results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88e4c7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T07:04:53.888093Z",
     "start_time": "2022-12-08T07:04:53.885304Z"
    }
   },
   "source": [
    "# Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "12aa46f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T17:06:38.221077Z",
     "start_time": "2022-12-08T17:06:38.207513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>epoch</th>\n",
       "      <th>top1</th>\n",
       "      <th>top5</th>\n",
       "      <th>loss</th>\n",
       "      <th>time</th>\n",
       "      <th>layer</th>\n",
       "      <th>layer_params</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>hidden_layer_dim</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>invariant</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0.36598</td>\n",
       "      <td>0.84058</td>\n",
       "      <td>388.795895</td>\n",
       "      <td>13.6</td>\n",
       "      <td>0</td>\n",
       "      <td>789258</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>256</td>\n",
       "      <td>250</td>\n",
       "      <td>False</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3645</td>\n",
       "      <td>0.8369</td>\n",
       "      <td>73.113495</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>789258</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>256</td>\n",
       "      <td>250</td>\n",
       "      <td>False</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>358.392616</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0</td>\n",
       "      <td>789258</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>256</td>\n",
       "      <td>250</td>\n",
       "      <td>False</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>789258</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>256</td>\n",
       "      <td>250</td>\n",
       "      <td>False</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>345.389089</td>\n",
       "      <td>12.4</td>\n",
       "      <td>0</td>\n",
       "      <td>789258</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>256</td>\n",
       "      <td>250</td>\n",
       "      <td>False</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>test</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>7</td>\n",
       "      <td>789258</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>256</td>\n",
       "      <td>250</td>\n",
       "      <td>False</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>train</td>\n",
       "      <td>9</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>220.868749</td>\n",
       "      <td>25.6</td>\n",
       "      <td>7</td>\n",
       "      <td>789258</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>256</td>\n",
       "      <td>250</td>\n",
       "      <td>False</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>test</td>\n",
       "      <td>9</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>7</td>\n",
       "      <td>789258</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>256</td>\n",
       "      <td>250</td>\n",
       "      <td>False</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>train</td>\n",
       "      <td>10</td>\n",
       "      <td>0.6297</td>\n",
       "      <td>0.95828</td>\n",
       "      <td>219.755396</td>\n",
       "      <td>26.9</td>\n",
       "      <td>7</td>\n",
       "      <td>789258</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>256</td>\n",
       "      <td>250</td>\n",
       "      <td>False</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>test</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5316</td>\n",
       "      <td>0.9332</td>\n",
       "      <td>53.668432</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>7</td>\n",
       "      <td>789258</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>256</td>\n",
       "      <td>250</td>\n",
       "      <td>False</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     type  epoch     top1     top5        loss  time  layer  layer_params  \\\n",
       "0   train      0  0.36598  0.84058  388.795895  13.6      0        789258   \n",
       "1    test      0   0.3645   0.8369   73.113495  <NA>      0        789258   \n",
       "2   train      1     <NA>     <NA>  358.392616  12.5      0        789258   \n",
       "3    test      1     <NA>     <NA>        <NA>  <NA>      0        789258   \n",
       "4   train      2     <NA>     <NA>  345.389089  12.4      0        789258   \n",
       "..    ...    ...      ...      ...         ...   ...    ...           ...   \n",
       "17   test      8     <NA>     <NA>        <NA>  <NA>      7        789258   \n",
       "18  train      9     <NA>     <NA>  220.868749  25.6      7        789258   \n",
       "19   test      9     <NA>     <NA>        <NA>  <NA>      7        789258   \n",
       "20  train     10   0.6297  0.95828  219.755396  26.9      7        789258   \n",
       "21   test     10   0.5316   0.9332   53.668432  <NA>      7        789258   \n",
       "\n",
       "                          optimizer  hidden_layer_dim  batch_size  invariant  \\\n",
       "0   <class 'torch.optim.adam.Adam'>               256         250      False   \n",
       "1   <class 'torch.optim.adam.Adam'>               256         250      False   \n",
       "2   <class 'torch.optim.adam.Adam'>               256         250      False   \n",
       "3   <class 'torch.optim.adam.Adam'>               256         250      False   \n",
       "4   <class 'torch.optim.adam.Adam'>               256         250      False   \n",
       "..                              ...               ...         ...        ...   \n",
       "17  <class 'torch.optim.adam.Adam'>               256         250      False   \n",
       "18  <class 'torch.optim.adam.Adam'>               256         250      False   \n",
       "19  <class 'torch.optim.adam.Adam'>               256         250      False   \n",
       "20  <class 'torch.optim.adam.Adam'>               256         250      False   \n",
       "21  <class 'torch.optim.adam.Adam'>               256         250      False   \n",
       "\n",
       "   model  \n",
       "0    MLP  \n",
       "1    MLP  \n",
       "2    MLP  \n",
       "3    MLP  \n",
       "4    MLP  \n",
       "..   ...  \n",
       "17   MLP  \n",
       "18   MLP  \n",
       "19   MLP  \n",
       "20   MLP  \n",
       "21   MLP  \n",
       "\n",
       "[176 rows x 13 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_bp_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "fcf7e4f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T17:06:38.751590Z",
     "start_time": "2022-12-08T17:06:38.745801Z"
    }
   },
   "outputs": [],
   "source": [
    "mlp_bp_results_df.to_csv(workdir + f'results/{str(dt.strftime(\"%Y-%m-%d-%H-%M\"))}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "6e24dbcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T17:07:14.549667Z",
     "start_time": "2022-12-08T17:06:39.205381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW!\n",
      "cpu\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Starting epoch 1\n",
      "Train Acc: 0.3466\n",
      "Test Acc: 0.3523\n",
      "Loss: 393.2909264564514\n",
      "Time: 12.7\n",
      "0\n",
      "393.2909264564514\n"
     ]
    }
   ],
   "source": [
    "mlp_bp_model, mlp_bp_results_df = full_backprop_training(models.LayerwiseConfigurableMLP())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1aa4a9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-08T17:06:39.829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW!\n",
      "cpu\n",
      "====================================================================================================\n",
      ">>> TRAINING THE BASE MODEL:\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Starting epoch 1\n"
     ]
    }
   ],
   "source": [
    "mlp_model, mlp_results_df = greedy_layerwise_training(models.LayerwiseConfigurableMLP())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180cd1a4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-08T17:06:41.418Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_model, cnn_results_df = greedy_layerwise_training(models.LayerwiseConfigurableCNN())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532fb1cd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-08T17:06:43.565Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_bp_model, cnn_bp_results_df = full_backprop_training(models.LayerwiseConfigurableCNN())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb1450b",
   "metadata": {},
   "source": [
    "Questions\n",
    "\n",
    "1) Understanding the curvature of the loss function - how to compute the Hessian\n",
    "2) Should I freeze the output layer?\n",
    "3) What does it mean to set W_L using the neural collapse property?\n",
    "4) Skip connections - does that mean that each layer needs to have the same output dimension as the final output dimension? Do we just sum them up at the end\n",
    "5) Training Resources\n",
    "6) Weight Decay? Batch Normalization?\n",
    "7) Width of Hidden Layers in MLP\n",
    "\n",
    "8) Depth of MLP\n",
    "9) Number of Channels in CNN\n",
    "10) Kernel Size in CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9340c5",
   "metadata": {},
   "source": [
    "Lecture\n",
    "\n",
    "1) Understanding, as a mathematician, the critical points of L\n",
    "2) Goal\n",
    "\n",
    "\n",
    "For deep (l >= 3) nonlinear networks, bad local (non-global) minimima exist - that are difficult to escape\n",
    "Morse Function. A function L: R^d -> R is MOrse if at every critical point p in R^d the Hessian Hess(L) (p) is nonsingular (i.e. has no 0 eigenvalues)\n",
    "\n",
    "1) If L is Morse, can understand the topology of u by computing all the critical points of L and geometry near them\n",
    "2) Almost every c^2 function is Morse (Morse functions are open, dense in C^2)\n",
    "\n",
    "Morse-Bott function\n",
    "Allow for non-isolated critical points\n",
    "L: R^d -> R is Morse Bott f critical locus is a closed submanifold and Hess(L) is nonsingular in normal directions to that submanifold\n",
    "\n",
    "Geometry changes significantly across regimes\n",
    "- width > n\n",
    "- width > poly(n)\n",
    "- width > sqrt(n)\n",
    "\n",
    "As soon as there exists "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "324px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
